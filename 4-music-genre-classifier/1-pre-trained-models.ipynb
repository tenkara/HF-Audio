{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to c:\\users\\raj\\appdata\\local\\temp\\pip-req-build-8erxjlxl\n",
      "  Resolved https://github.com/huggingface/transformers to commit e538189931a0615b56ed96fae9f9cb3418644802\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-1.25.1-cp311-cp311-win_amd64.whl (15.0 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from transformers==4.31.0.dev0) (23.1)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp311-cp311-win_amd64.whl (143 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.6.3-cp311-cp311-win_amd64.whl (268 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.3.1-cp311-cp311-win_amd64.whl (263 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers==4.31.0.dev0) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.2.0-cp311-cp311-win_amd64.whl (96 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml): started\n",
      "  Building wheel for transformers (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for transformers: filename=transformers-4.31.0.dev0-py3-none-any.whl size=7348045 sha256=b5aeeacc69effa6323b22f3f532dab02708b86b72c4b403141015e533239ce5d\n",
      "  Stored in directory: C:\\Users\\Raj\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-kfcccmeu\\wheels\\04\\a3\\f1\\b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, safetensors, urllib3, typing-extensions, tqdm, regex, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, transformers\n",
      "Successfully installed certifi-2023.5.7 charset-normalizer-3.2.0 filelock-3.12.2 fsspec-2023.6.0 huggingface-hub-0.16.4 idna-3.4 numpy-1.25.1 pyyaml-6.0 regex-2023.6.3 requests-2.31.0 safetensors-0.3.1 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.31.0.dev0 typing-extensions-4.7.1 urllib3-2.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers 'C:\\Users\\Raj\\AppData\\Local\\Temp\\pip-req-build-8erxjlxl'\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (22.3.1)\n",
      "Collecting pip\n",
      "  Using cached pip-23.1.2-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.3.1\n",
      "    Uninstalling pip-22.3.1:\n",
      "      Successfully uninstalled pip-22.3.1\n",
      "Successfully installed pip-23.1.2\n"
     ]
    }
   ],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyword Spotting (KWS) is the task of identifying a keyword in a spoken utterance. The set of keywords forms the set of predicted class labels. Hence, to use a pre-trained keyword spotting model, you should ensure that your keywords match those that the model was pre-trained on. Below, weâ€™ll introduce **two datasets and models** for keyword spotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minds-14**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-2.13.1-py3-none-any.whl (486 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from datasets) (1.25.1)\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Using cached pyarrow-12.0.1-cp311-cp311-win_amd64.whl (21.5 MB)\n",
      "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.0.3-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.2.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Using cached multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from datasets) (2023.6.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.8.4-cp311-cp311-win_amd64.whl (317 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from datasets) (6.0)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.9.2-cp311-cp311-win_amd64.whl (60 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "                                              0.0/44.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.9/44.9 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas->datasets)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\raj\\repos\\hf-audio\\4-music-genre-classifier\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, multidict, frozenlist, dill, attrs, async-timeout, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 attrs-23.1.0 datasets-2.13.1 dill-0.3.6 frozenlist-1.4.0 multidict-6.0.4 multiprocess-0.70.14 pandas-2.0.3 pyarrow-12.0.1 pytz-2023.3 tzdata-2023.3 xxhash-3.2.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[0;32m      2\u001b[0m \u001b[39m# import minds-14k dataset\u001b[39;00m\n\u001b[0;32m      3\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39m\u001b[39mPolyAI/minds14\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39men-AU\u001b[39m\u001b[39m\"\u001b[39m, split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# import minds-14k dataset\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-AU\", split=\"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
